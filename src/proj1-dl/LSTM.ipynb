{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import dlc_bci as bci\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target = bci.load(root = './data_bci', one_khz=True)\n",
    "print(str(type(train_input)), train_input.size()) \n",
    "print(str(type(train_target)), train_target.size())\n",
    "X = train_input.numpy()\n",
    "y = train_target.numpy()\n",
    "kfolds = model_selection.KFold(n_splits=10, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 500])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "test_input , test_target = bci.load(root = './data_bci', train = False, one_khz=True)\n",
    "print(str(type(test_input)), test_input.size()) \n",
    "print(str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization is done!\n"
     ]
    }
   ],
   "source": [
    "# put this inside the train to avoid data snooping\n",
    "mu, std = train_input.mean(0), train_input.std(0)\n",
    "train_input.sub_(mu).div_(std)\n",
    "test_input.sub_(mu).div_(std)\n",
    "print(\"Normalization is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import compute_nb_errors\n",
    "\n",
    "\n",
    "def train_model_full(network_model,\n",
    "                     param,\n",
    "                     X, y,\n",
    "                     mini_batch_size,\n",
    "                     kfolds,\n",
    "                     nb_epochs,\n",
    "                     lambdda=0.01,\n",
    "                     lr=0.001,\n",
    "                     verbose=False):\n",
    "    acc_train_kfold = []\n",
    "    loss_train_kfold = []\n",
    "    acc_val_kfold = []\n",
    "    loss_val_kfold = []\n",
    "\n",
    "    for d, (train_index, val_index) in enumerate(kfolds.split(X)):\n",
    "        if verbose:\n",
    "            print('\\nFold {}'.format(d))\n",
    "            print('----------------------------------------------------------------')\n",
    "\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        X_train = Variable(torch.from_numpy(X_train))\n",
    "        X_val = Variable(torch.from_numpy(X_val))\n",
    "        y_train = Variable(torch.from_numpy(y_train))\n",
    "        y_val = Variable(torch.from_numpy(y_val))\n",
    "\n",
    "        model = network_model(**param)\n",
    "\n",
    "        loss_train, loss_val, acc_train, acc_val = train_model(model,\n",
    "                                                               X_train, y_train,\n",
    "                                                               X_val, y_val,\n",
    "                                                               mini_batch_size,\n",
    "                                                               nb_epochs,\n",
    "                                                               lambdda, lr,\n",
    "                                                               verbose)\n",
    "        acc_train_kfold.append(acc_train)\n",
    "        loss_train_kfold.append(loss_train)\n",
    "        acc_val_kfold.append(acc_val)\n",
    "        loss_val_kfold.append(loss_val)\n",
    "\n",
    "    acc_train_kfold = np.mean(np.array(acc_train_kfold), axis=0)\n",
    "    acc_val_kfold = np.mean(np.array(acc_val_kfold), axis=0)\n",
    "\n",
    "    loss_train_kfold = np.mean(np.array(loss_train_kfold), axis=0)\n",
    "    loss_val_kfold = np.mean(np.array(loss_val_kfold), axis=0)\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    print('{} epochs done for `{}` with the parameters:'.format(nb_epochs, network_model.__name__))\n",
    "    pp.pprint(param)\n",
    "    print('\\n   Loss: train ~ {} Acc train ~ {} \\n   Loss: val ~ {} / Acc val ~ {}'\n",
    "          .format(round(loss_train_kfold[-1], 3),\n",
    "                  round(acc_train_kfold[-1], 3),\n",
    "                  round(loss_val_kfold[-1], 3),\n",
    "                  round(acc_val_kfold[-1], 3)))\n",
    "    print('----------------------------------------------------------------')\n",
    "    return loss_train_kfold, loss_val_kfold, acc_train_kfold, acc_val_kfold\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, mini_batch_size, nb_epochs, lambdda=0.01, lr=0.001,\n",
    "                verbose=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    acc_train = []\n",
    "    acc_val = []\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "\n",
    "    for e in range(0, nb_epochs):\n",
    "\n",
    "        model.train(True)\n",
    "        for b in list(range(0, X_train.size(0), mini_batch_size)):\n",
    "            if b + mini_batch_size <= X_train.size(0):\n",
    "                output = model(X_train.narrow(0, b, mini_batch_size))\n",
    "                loss = criterion(output, y_train.narrow(0, b, mini_batch_size))\n",
    "            else:\n",
    "                output = model(X_train.narrow(0, b, X_train.size(0) - b))\n",
    "                loss = criterion(output, y_train.narrow(0, b, X_train.size(0) - b))\n",
    "\n",
    "            for p in model.parameters():\n",
    "                loss += lambdda * p.pow(2).sum()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.train(False)\n",
    "            output_train = model(X_train)\n",
    "            output_val = model(X_val)\n",
    "\n",
    "        acc_val.append(1 - compute_nb_errors(model, X_val, y_val, mini_batch_size=mini_batch_size) / X_val.size(0))\n",
    "        acc_train.append(\n",
    "            1 - compute_nb_errors(model, X_train, y_train, mini_batch_size=mini_batch_size) / X_train.size(0))\n",
    "        loss_train.append(criterion(output_train, y_train).data[0])\n",
    "        loss_val.append(criterion(output_val, y_val).data[0])\n",
    "\n",
    "        if verbose and (e-1) % 100 == 0:\n",
    "            print('Epoch {}, accuracy in validation: {} / train {}'.format(e, round(acc_val[-1], 3), round(acc_train[-1], 3)))\n",
    "\n",
    "    return loss_train, loss_val, acc_train, acc_val\n",
    "\n",
    "\n",
    "def train_parallel(param):\n",
    "    train_model_full(**param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target, mini_batch_size):\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        if b + mini_batch_size <= data_input.size(0):\n",
    "            output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "            _, predicted_classes = torch.max(output.data, 1)\n",
    "            for k in range(0, mini_batch_size):\n",
    "                if data_target.data[b + k] != predicted_classes[k]:\n",
    "                    nb_data_errors = nb_data_errors + 1\n",
    "        else:\n",
    "            output = model(data_input.narrow(0, b, data_input.size(0) - b))\n",
    "            _, predicted_classes = torch.max(output.data, 1)\n",
    "            for k in range(0, data_input.size(0) - b):\n",
    "                if data_target.data[b + k] != predicted_classes[k]:\n",
    "                    nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI_BATCH_SIZE = 40\n",
    "N_EPOCHS = 3\n",
    "N_FOLDS = 10\n",
    "kfolds = model_selection.KFold(n_splits=N_FOLDS, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size,\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.rnn = nn.LSTM(         \n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,         \n",
    "            num_layers=1,           \n",
    "            batch_first=True,  \n",
    "            dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h_n, h_c) = self.rnn(x, None) # zero initial hidden state\n",
    "        out = self.out(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.531 / train 0.644\n",
      "Epoch 101, accuracy in validation: 0.25 / train 0.648\n",
      "Epoch 201, accuracy in validation: 0.281 / train 0.69\n",
      "Epoch 301, accuracy in validation: 0.344 / train 0.68\n",
      "Epoch 401, accuracy in validation: 0.406 / train 0.722\n",
      "Epoch 501, accuracy in validation: 0.344 / train 0.757\n",
      "\n",
      "Fold 1\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.594 / train 0.532\n",
      "Epoch 101, accuracy in validation: 0.625 / train 0.697\n",
      "Epoch 201, accuracy in validation: 0.719 / train 0.676\n",
      "Epoch 301, accuracy in validation: 0.594 / train 0.778\n",
      "Epoch 401, accuracy in validation: 0.562 / train 0.82\n",
      "Epoch 501, accuracy in validation: 0.594 / train 0.683\n",
      "\n",
      "Fold 2\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.469 / train 0.602\n",
      "Epoch 101, accuracy in validation: 0.375 / train 0.701\n",
      "Epoch 201, accuracy in validation: 0.406 / train 0.725\n",
      "Epoch 301, accuracy in validation: 0.469 / train 0.761\n",
      "Epoch 401, accuracy in validation: 0.531 / train 0.813\n",
      "Epoch 501, accuracy in validation: 0.469 / train 0.799\n",
      "\n",
      "Fold 3\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.438 / train 0.577\n",
      "Epoch 101, accuracy in validation: 0.531 / train 0.69\n",
      "Epoch 201, accuracy in validation: 0.625 / train 0.676\n",
      "Epoch 301, accuracy in validation: 0.562 / train 0.701\n",
      "Epoch 401, accuracy in validation: 0.625 / train 0.673\n",
      "Epoch 501, accuracy in validation: 0.531 / train 0.669\n",
      "\n",
      "Fold 4\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.438 / train 0.592\n",
      "Epoch 101, accuracy in validation: 0.5 / train 0.644\n",
      "Epoch 201, accuracy in validation: 0.625 / train 0.715\n",
      "Epoch 301, accuracy in validation: 0.469 / train 0.701\n",
      "Epoch 401, accuracy in validation: 0.469 / train 0.708\n",
      "Epoch 501, accuracy in validation: 0.594 / train 0.775\n",
      "\n",
      "Fold 5\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.531 / train 0.535\n",
      "Epoch 101, accuracy in validation: 0.406 / train 0.669\n",
      "Epoch 201, accuracy in validation: 0.5 / train 0.704\n"
     ]
    }
   ],
   "source": [
    "costs, costs_val, acc, acc_val = train_model_full(RNN,\n",
    "                                                              {'input_size': 500,\n",
    "                                                               'output_size': 1,\n",
    "                                                               'hidden_size': 128,\n",
    "                                                               'dropout': 0.1},\n",
    "                                                              X,\n",
    "                                                              y,\n",
    "                                                              MINI_BATCH_SIZE,\n",
    "                                                              kfolds,\n",
    "                                                              502,\n",
    "                                                              lambdda=0.0375, \n",
    "                                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
