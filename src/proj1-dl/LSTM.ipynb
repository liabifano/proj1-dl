{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import dlc_bci as bci\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([316, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([316])\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target = bci.load(root = './data_bci')\n",
    "print(str(type(train_input)), train_input.size()) \n",
    "print(str(type(train_target)), train_target.size())\n",
    "X = train_input.numpy()\n",
    "y = train_target.numpy()\n",
    "kfolds = model_selection.KFold(n_splits=10, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.FloatTensor'> torch.Size([100, 28, 50])\n",
      "<class 'torch.LongTensor'> torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "test_input , test_target = bci.load(root = './data_bci', train = False)\n",
    "print(str(type(test_input)), test_input.size()) \n",
    "print(str(type(test_target)), test_target.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization is done!\n"
     ]
    }
   ],
   "source": [
    "# put this inside the train to avoid data snooping\n",
    "mu, std = train_input.mean(0), train_input.std(0)\n",
    "train_input.sub_(mu).div_(std)\n",
    "test_input.sub_(mu).div_(std)\n",
    "print(\"Normalization is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils import compute_nb_errors\n",
    "\n",
    "\n",
    "def train_model_full(network_model,\n",
    "                     param,\n",
    "                     X, y,\n",
    "                     mini_batch_size,\n",
    "                     kfolds,\n",
    "                     nb_epochs,\n",
    "                     lambdda=0.01,\n",
    "                     lr=0.001,\n",
    "                     verbose=False):\n",
    "    acc_train_kfold = []\n",
    "    loss_train_kfold = []\n",
    "    acc_val_kfold = []\n",
    "    loss_val_kfold = []\n",
    "\n",
    "    for d, (train_index, val_index) in enumerate(kfolds.split(X)):\n",
    "        if verbose:\n",
    "            print('\\nFold {}'.format(d))\n",
    "            print('----------------------------------------------------------------')\n",
    "\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        X_train = Variable(torch.from_numpy(X_train))\n",
    "        X_val = Variable(torch.from_numpy(X_val))\n",
    "        y_train = Variable(torch.from_numpy(y_train))\n",
    "        y_val = Variable(torch.from_numpy(y_val))\n",
    "\n",
    "        model = network_model(**param)\n",
    "\n",
    "        loss_train, loss_val, acc_train, acc_val = train_model(model,\n",
    "                                                               X_train, y_train,\n",
    "                                                               X_val, y_val,\n",
    "                                                               mini_batch_size,\n",
    "                                                               nb_epochs,\n",
    "                                                               lambdda, lr,\n",
    "                                                               verbose)\n",
    "        acc_train_kfold.append(acc_train)\n",
    "        loss_train_kfold.append(loss_train)\n",
    "        acc_val_kfold.append(acc_val)\n",
    "        loss_val_kfold.append(loss_val)\n",
    "\n",
    "    acc_train_kfold = np.mean(np.array(acc_train_kfold), axis=0)\n",
    "    acc_val_kfold = np.mean(np.array(acc_val_kfold), axis=0)\n",
    "\n",
    "    loss_train_kfold = np.mean(np.array(loss_train_kfold), axis=0)\n",
    "    loss_val_kfold = np.mean(np.array(loss_val_kfold), axis=0)\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    print('{} epochs done for `{}` with the parameters:'.format(nb_epochs, network_model.__name__))\n",
    "    pp.pprint(param)\n",
    "    print('\\n   Loss: train ~ {} Acc train ~ {} \\n   Loss: val ~ {} / Acc val ~ {}'\n",
    "          .format(round(loss_train_kfold[-1], 3),\n",
    "                  round(acc_train_kfold[-1], 3),\n",
    "                  round(loss_val_kfold[-1], 3),\n",
    "                  round(acc_val_kfold[-1], 3)))\n",
    "    print('----------------------------------------------------------------')\n",
    "    return loss_train_kfold, loss_val_kfold, acc_train_kfold, acc_val_kfold\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val, mini_batch_size, nb_epochs, lambdda=0.01, lr=0.001,\n",
    "                verbose=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    acc_train = []\n",
    "    acc_val = []\n",
    "    loss_train = []\n",
    "    loss_val = []\n",
    "\n",
    "    for e in range(0, nb_epochs):\n",
    "\n",
    "        model.train(True)\n",
    "        for b in list(range(0, X_train.size(0), mini_batch_size)):\n",
    "            if b + mini_batch_size <= X_train.size(0):\n",
    "                output = model(X_train.narrow(0, b, mini_batch_size))\n",
    "                loss = criterion(output, y_train.narrow(0, b, mini_batch_size))\n",
    "            else:\n",
    "                output = model(X_train.narrow(0, b, X_train.size(0) - b))\n",
    "                loss = criterion(output, y_train.narrow(0, b, X_train.size(0) - b))\n",
    "\n",
    "            for p in model.parameters():\n",
    "                loss += lambdda * p.pow(2).sum()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            model.train(False)\n",
    "            output_train = model(X_train)\n",
    "            output_val = model(X_val)\n",
    "\n",
    "        acc_val.append(1 - compute_nb_errors(model, X_val, y_val, mini_batch_size=mini_batch_size) / X_val.size(0))\n",
    "        acc_train.append(\n",
    "            1 - compute_nb_errors(model, X_train, y_train, mini_batch_size=mini_batch_size) / X_train.size(0))\n",
    "        loss_train.append(criterion(output_train, y_train).data[0])\n",
    "        loss_val.append(criterion(output_val, y_val).data[0])\n",
    "\n",
    "        if verbose and (e-1) % 100 == 0:\n",
    "            print('Epoch {}, accuracy in validation: {} / train {}'.format(e, round(acc_val[-1], 3), round(acc_train[-1], 3)))\n",
    "\n",
    "    return loss_train, loss_val, acc_train, acc_val\n",
    "\n",
    "\n",
    "def train_parallel(param):\n",
    "    train_model_full(**param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target, mini_batch_size):\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        if b + mini_batch_size <= data_input.size(0):\n",
    "            output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "            _, predicted_classes = torch.max(output.data, 1)\n",
    "            for k in range(0, mini_batch_size):\n",
    "                if data_target.data[b + k] != predicted_classes[k]:\n",
    "                    nb_data_errors = nb_data_errors + 1\n",
    "        else:\n",
    "            output = model(data_input.narrow(0, b, data_input.size(0) - b))\n",
    "            _, predicted_classes = torch.max(output.data, 1)\n",
    "            for k in range(0, data_input.size(0) - b):\n",
    "                if data_target.data[b + k] != predicted_classes[k]:\n",
    "                    nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_net(nn.Module):\n",
    "    def __init__(self, size, layers, layers_conv, kernel_size, pooling_kernel_size, p):\n",
    "        super(Conv_net, self).__init__()\n",
    "        self.pooling_kernel_size = pooling_kernel_size\n",
    "        self.additional_conv_hidden = nn.ModuleList()\n",
    "        self.additional_fc_hidden = nn.ModuleList()\n",
    "        self.droput_layers = nn.ModuleList()\n",
    "        self.batch_normalization = nn.ModuleList()\n",
    "        self.size = size\n",
    "\n",
    "        for l in range(len(layers_conv) - 1):\n",
    "            self.additional_conv_hidden.append(\n",
    "                nn.Conv1d(layers_conv[l], layers_conv[l + 1], kernel_size=kernel_size[l]))\n",
    "            self.droput_layers.append(torch.nn.Dropout(p=p[l]))\n",
    "            self.batch_normalization.append(torch.nn.BatchNorm1d(layers_conv[l + 1]))\n",
    "\n",
    "        for i in range(len(kernel_size)):\n",
    "            size-=(kernel_size[i]-1)\n",
    "\n",
    "            size//=pooling_kernel_size[i]\n",
    "\n",
    "        self.additional_fc_hidden.append(nn.Linear(size * layers_conv[-1], layers[0]))\n",
    "        self.droput_layers.append(torch.nn.Dropout(p=p[l + 1]))\n",
    "        self.batch_normalization.append(torch.nn.BatchNorm1d(layers[0]))\n",
    "        self.flat_size = size * layers_conv[-1]\n",
    "\n",
    "        start_p = l + 2\n",
    "\n",
    "        for l in range(len(layers) - 1):\n",
    "            self.additional_fc_hidden.append(nn.Linear(layers[l], layers[l + 1]))\n",
    "            if l != len(layers) - 2:\n",
    "                self.droput_layers.append(torch.nn.Dropout(p=p[l + start_p]))\n",
    "                self.batch_normalization.append(torch.nn.BatchNorm1d(layers[l + 1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in range(len(self.additional_conv_hidden)):\n",
    "            x = self.droput_layers[l](self.batch_normalization[l](\n",
    "                F.relu(F.max_pool1d(self.additional_conv_hidden[l](x), kernel_size=self.pooling_kernel_size[l]))))\n",
    "        x = x.view(-1, self.flat_size)\n",
    "        for l in range(len(self.additional_fc_hidden) - 1):\n",
    "            index = len(self.additional_conv_hidden) + l\n",
    "            x = self.droput_layers[index](self.batch_normalization[index](F.relu(self.additional_fc_hidden[l](x))))\n",
    "        x = self.additional_fc_hidden[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "MINI_BATCH_SIZE = 40\n",
    "N_EPOCHS = 3\n",
    "N_FOLDS = 10\n",
    "kfolds = model_selection.KFold(n_splits=N_FOLDS, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {   'kernel_size': [2],\n",
    "                 'layers': [38, 10, 2],\n",
    "                 'layers_conv': [28, 12],\n",
    "                 'p': [0.562869316924044, 0.690112553456004, 0.22976692024847756],\n",
    "                 'pooling_kernel_size': [3],\n",
    "                 'size': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 epochs done for `Conv_net` with the parameters:\n",
      "{   'kernel_size': [2],\n",
      "    'layers': [38, 10, 2],\n",
      "    'layers_conv': [28, 12],\n",
      "    'p': [0.562869316924044, 0.690112553456004, 0.22976692024847756],\n",
      "    'pooling_kernel_size': [3],\n",
      "    'size': 50}\n",
      "\n",
      "   Loss: train ~ 0.696 Acc train ~ 0.499 \n",
      "   Loss: val ~ 0.7 / Acc val ~ 0.487\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "costs, costs_val, acc, acc_val = train_model_full(Conv_net,\n",
    "                                                              params,\n",
    "                                                              X,\n",
    "                                                              y,\n",
    "                                                              MINI_BATCH_SIZE,\n",
    "                                                              kfolds,\n",
    "                                                              N_EPOCHS,\n",
    "                                                              lambdda=0.0375)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size,\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.rnn = nn.LSTM(         \n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.hidden_size,         \n",
    "            num_layers=1,           \n",
    "            batch_first=True,  \n",
    "            dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (h_n, h_c) = self.rnn(x, None) # zero initial hidden state\n",
    "        out = self.out(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.406 / train 0.577\n",
      "Epoch 101, accuracy in validation: 0.312 / train 0.616\n",
      "\n",
      "Fold 1\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.531 / train 0.528\n",
      "Epoch 101, accuracy in validation: 0.531 / train 0.542\n",
      "\n",
      "Fold 2\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.531 / train 0.567\n",
      "Epoch 101, accuracy in validation: 0.562 / train 0.574\n",
      "\n",
      "Fold 3\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.5 / train 0.546\n",
      "Epoch 101, accuracy in validation: 0.5 / train 0.535\n",
      "\n",
      "Fold 4\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.344 / train 0.574\n",
      "Epoch 101, accuracy in validation: 0.5 / train 0.585\n",
      "\n",
      "Fold 5\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.531 / train 0.539\n",
      "Epoch 101, accuracy in validation: 0.406 / train 0.577\n",
      "\n",
      "Fold 6\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.452 / train 0.488\n",
      "Epoch 101, accuracy in validation: 0.548 / train 0.516\n",
      "\n",
      "Fold 7\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.613 / train 0.579\n",
      "Epoch 101, accuracy in validation: 0.613 / train 0.568\n",
      "\n",
      "Fold 8\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.29 / train 0.502\n",
      "Epoch 101, accuracy in validation: 0.484 / train 0.561\n",
      "\n",
      "Fold 9\n",
      "----------------------------------------------------------------\n",
      "Epoch 1, accuracy in validation: 0.548 / train 0.509\n",
      "Epoch 101, accuracy in validation: 0.548 / train 0.565\n",
      "102 epochs done for `RNN` with the parameters:\n",
      "{'dropout': 0.1, 'hidden_size': 128, 'input_size': 50, 'output_size': 1}\n",
      "\n",
      "   Loss: train ~ 0.677 Acc train ~ 0.564 \n",
      "   Loss: val ~ 0.71 / Acc val ~ 0.501\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "costs, costs_val, acc, acc_val = train_model_full(RNN,\n",
    "                                                              {'input_size': 50,\n",
    "                                                               'output_size': 1,\n",
    "                                                               'hidden_size': 128,\n",
    "                                                               'dropout': 0.1},\n",
    "                                                              X,\n",
    "                                                              y,\n",
    "                                                              MINI_BATCH_SIZE,\n",
    "                                                              kfolds,\n",
    "                                                              102,\n",
    "                                                              lambdda=0.0375, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316, 28, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
